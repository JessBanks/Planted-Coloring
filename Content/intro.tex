\section{Introduction}

% set of bits


\emph{Community detection in graphs} is a canonical and widely applicable problem in computer science and machine learning. The setup is both simple and flexible: we are shown a graph and asked for a coarse-grained description in the form of a partition of the vertices into `communities' with atypically many internal edges. The literature contains innumerable algorithms and approaches for this task, but perhaps the most fruitful has been a Bayesian perspective wherein we treat the graph as the output of some generative model, whose unknown parameters we attempt to estimate. In other words, we assume that there are some true and hidden community labels, and that the graph has been drawn probibalistically in a way that respects this `planted' structure.

Much of the existing literature on community detection concerns the \emph{stochastic block model (SBM)}. For now let us discuss the symmetric setting where we first partition $n$ vertices in to $k$ groups, and include each edge independently and with probability $\pin$ or $\pout$ depending on whether or not the labels of its endpoints coincide. Research in this area spans several decades, and it will not be fruitful to attempt a thorough review of the literature here; we refer the reader to [cite] for a survey. Most salient to us, however, is a rich theory of computational threshold phenomena which has emerged out of the past several years of collaboration between computer scientists, statisticians, and statistical physicists.

The key computational tasks associated with the SBM are \emph{recovery} and \emph{detection}: we attempt either to reconstruct the planted communities from the graph, or to decide whether a graph was drawn from the planted model or the \ER model with the same average degree. A set of fascinating conjectures were posed in Decelle \etal \cite{decelle2011inference}, regarding these tasks in the case of `sparse' models where $\pin,\pout = O(1/n)$ and the average degree is $O(1)$ as the number of vertices diverges. 

It is typical to parametrize the symmetric SBM in terms of $k$, the average degree
$$
	d = \frac{n\pin + (k-1)n\pout}{k},
$$
and a `signal-to-noise ratio'
$$
	\lambda \triangleq \frac{n\pin - n\pout}{kd}.
$$
In this setup, it is believed that as we hold $k$ and $\lambda$ constant, then there is an \emph{information-theoretic threshold} $d_{IT} \approx \tfrac{\log k}{k\lambda^2}$, in the sense that when $d<d_{IT}$ both detection and recovery are impossible for any algorithm. Moreover, Decelle et al. conjecture that efficient algorithms for both tasks exist only when the degree is larger than a point known as the \emph{Kesten-Stigum threshold} $d_{KS} = \lambda^{-2}$. Much of this picture is now rigorous \cite{mossel2018proof, massoulie2014community,bordenave2015non,abbe2016exact}. Still, fundamental questions remain unanswered. What evidence can we furnish that detection and recovery are indeed intractible in the so-called `hard regime' $d_{IT} < d < d_{KS}$? How robust are these thresholds to adversarial noise or small deviations from the model?

Zooming out, this discrepancy between information-theoretic and computational thresholds is conjectured to be quite universal among planted problems, where we are to reconstruct or detect a structured, high-dimensional signal observed through a noisy channel [citaions]. The purpose behind our work is to begin developing a framework capable of providing evidence for average case computational intractability in such settings. To illustrate this broader motivation, consider a different average-case problem also conjectured to be computationally intractable: refutation of random $3$-SAT. A random instance of $3$-SAT with $n$ literals and, say $m = 1000 n$ clauses is unsatisfiable with high probability. However, it is widely conjectured that the problem of \emph{certifying} that a given random $3$-SAT instance is unsatisfiable is computationally intractable (all the way up to $n^{3/2}$ clauses) \cite{feigerandom3sat}. While proving intractability remains out of reach, the complexity theoretic literature now contains ample evidence in support of this conjecture. Most prominently, exponential lower bounds are known for the problem in restricted computational models such as linear and semidefinite programs \cite{grigoriev2001linear} and resolution based proofs \cite{ben2001short}. Within the context of combinatorial optimization, the Sum-of-Squares (SoS) SDPs yield a hierarchy of sucessively more powerful and complex algorithms which capture and unify many other known approaches. A lower bound against the SoS SDP hierarchy such as \cite{grigoriev2001linear} provides strong evidence that this refutation problem is computationally intractable. This paper is a step towards developing a similar framework to reason about the computational complexity of detection and recovery in stochastic block models specifically, and planted problems generally. \todo{Mention Sam/David/etc.'s work here?}

A second motivation is the issue of robustness of computational thresholds under adversarial perturbations of the graph. Spectral algorithms based on non-backtracking walk matrix \cite{bordenave2015non} achieve weak-detection as soon as $d> d_{KS}$, but are not robust in this sense. Conversely, robust algorithms for recovery are known, but only when the edge-densities are significantly higher than Kesten-Stigum \cite{guedon2016community,makarychev2016learning,CharikarSV17,SteinhardtVC16}. The positive result that gets closest to robustly achieving the conjectured computational phase transition at $d_{KS}$ is the work of Montanari and Sen \cite{montanari2015semidefinite} who observe that their SDP-based algorithm for testing whether the input graph comes from the \ER distribution or a Stochastic Block Model with $k = 2$ communities also works in presence of $o(|E|)$ edge outlier errors.  On the negative side, Moitra et al. \cite{moitra2012singly} consider the problem of weak recovery in a SBM with two communities and $\pin > \pout$ in the presence of {\it monotone errors} that add edges within communities and delete edges between them. Their main result is a statistical lower bound indicating the phase transition for weak recovery changes in the presence of monotone errors. This still leaves open the question of whether there exist algorithms that weakly recover right at the threshold and are robust to $o(|E|)$ perturbations in the graph. \todo{Cite recent result on robustness?}

\section{Main Results} % (fold)
\label{sec:main_results}

We define a new hierarchy of semidefinite programming relaxations for inference problems that we refer to as the \emph{Local Statistics} hierarchy, denoted $\LS(D_1,D_2)$ and indexed by parameters $D_1,D_2 \in \N$. This family of SDPs is inspired by the technique of pseudocalibration in proving lower bounds for sum-of-squares (SoS) relaxations, as well as subsequent work of Hopkins and Steurer \cite{hopkins2017efficient} extending it to an SoS SDP based approach to inference problems. The $\LS$ hierarchy can be defined for a broad range of inference problems involving a joint distribution $\mu$ on an observation and hidden parameter.

As a test case, we apply our SDP relaxations to community detection in the \emph{\fullmodel~(\model)}, a family of distributions over degree regular graphs with planted community structure. The degree-regularity will simplify some aspects of our analysis, allowing us to illustrate key features of the $\LS$ hierarchy without a proliferation of technicalities. We will comment later on about the possibilities for extension to the irregular case. As an aside, we cannot help but editorialize briefly that, although the \model is less useful in practice than the standard block model discussed above, its combinatorics are intricate and beautiful in their own right, and the related case of $d$-regular graphs with planted colorings have been quite well-studied [citations].

We will specify the DRBM on $n$ vertices in full generality by several parameters: the number of communities $k$, degree $d$, and a $k\times k$ transition matrix $M$ for a reversible Markov chain, with stationary distribution $\pi$. In other words, $M$ has row sums equal to one, and $\Diag(\pi) M$ is a symmetric matrix. To sample a graph $\bG = (\bV, \bE)$---we will use bold-face type for random objects throughout the paper---first partition the $n$ vertices randomly into $k$ groups $\bV_1,...,\bV_k$ with $|\bV_i| = \pi(i)n$, and then choose a $d$-regular random graph conditional on there being $\pi(i)M_{i,j} d n$ edges between groups $i\neq j$ and $\pi(i)M_{i,i} dn/2$ internal to each group $i$. As $\Diag(\pi) M$ is symmetric, this process is well-defined. We will assume always that the parameters are set to make these quantities integer-valued; settings for which this holds infinitely often as $n\to\infty$ are dense in the parameter space. 

\begin{remark}
	The \model~as we have defined it differs from the Regular Stochastic Block Model of [cite], in which each vertex has a prescribed number of neighbors in every community. Although superficially similar, the behavior of this `equitable' model (as it is known in the physics literature [cite]) is quite different from ours. For instance, [cite] show that whenever detection is possible, one can recover the community labels \emph{exactly}. This is not true in our case. \todo{Sketch why. Also should we change the name?}
\end{remark}

The \model~contains several more familiar distributions as special cases, and the reader is welcome to focus on her favorite for concreteness. When $\pi(i) = 1/k$ for every $i$, we have the \model~with equal groups. Setting $M_{i,i} = 0$ and $M_{i,j} = \tfrac{1}{k-1}$, we are in a somewhat restrictive case of the planted $k$-coloring model, where each pair of color classes has the same number of edges between them. We will refer to the case when $M_{i,i} = m_{\textup{in}}$ and $m_{\textup{out}}$ otherwise as the symmetric \model. As $M$ describes a reversible Markov chain, its spectrum is real, and we will write its eigenvalues as $1 = \lambda_1 \ge |\lambda_2| \ge \cdots \ge |\lambda_k|$. The second eigenvalue $\lambda_2$ can be thought of as a kind of signal-to-noise ratio, and will be repeatedly important to our analysis. One can verify, for instance, that in the case of the symmetric RSBM, $\lambda_2 = \cdots = \lambda_n = m_{\textup{in}} - m_{\textup{out}}$.

It is widely believed that the threshold behavior of the \model~is similar to that of the SBM, though the inhomogeneities in group size and edge density we allow for make the situation somewhat more complicated than in the symmetric case discussed earlier. This phenomenology includes an information-theoretic threshold $d_{IT} \approx \frac{\log k}{k\lambda_2^2}$ for the symmetric \model~(and a more complicated characterization in general that will not be relevant to us here). In the general model, the Kesten-Stigum threshold for \emph{detection} is $d_{KS} \triangleq \lambda_2^{-2} + 1$, and we expect recovery of \emph{all} communities once $d> 1/\lambda_k^2 + 1$. However, most formal treatment in the literature has been limited to the distribution of $d$-regular graphs conditional on having a planted $k$-coloring, a case not fully captured by our model [citations]. Characterization of the information-theoretic threshold, even for the symmetric \model remains largely folklore, and in Appendix [ref] we will for good measure provide a few rigorous pieces of the picture. 

Our main theorem is that the the Local Statistics hierarchy can robustly solve the detection problem on the \model whenever $d > d_{KS}$, but that otherwise any constant level fails to do so.

\begin{theorem} \label{thm:main}
	For every $\epsilon > 0$, and set of parameters $(d,k,M,\pi)$ satisfying $d > d_{KS} + \epsilon = 1/\lambda_2^2 + 1 + \epsilon$, there exists $m \in \bbN$ sufficiently large so that with probability $1-o(1)$ the $\LS(2,m)$ SDP, given an input graph $\bG$, can distinguish in time [need] whether
	\begin{itemize}
		\item $\bG$ is a uniformly random $d$-regular graph
		\item $\bG$ is sampled from the \model with parameters $(d,k,M,\pi)$
	\end{itemize}
	and is robust to adversarial addition or deletion of $o(n)$ edges. On the other hand, for any constant $m$ and $d< d_{KS}$, the $\LS(2,m)$ SDP fails with probability $1 - o(1)$ to distinguish.
\end{theorem}

% \noindent It is a priori possible that one could achieve the KS threshold without taking $m\to \infty$. However, we show that this cannot be true in general.

% \begin{theorem}
%     For every $m\in\bbN$ and $C\ge 1$, there exists a parameter set $(d,k,M,\pi)$ for which $d > d_{KS} + C$ but $\LS(2,m)$ cannot solve the detection problem.
% \end{theorem}

We also prove a stronger robustness guarantee, in particular that that $\LS(2,m)$ can tolerate $\epsilon_m n$ adversarial edge perturbations, although $\epsilon_m \to 0$ as we move up the hierarchy. This creates a trade-off between robustness, which we lose as added information is incorporated to the SDP at each successive level, and fidelity to the threshold, which we approach as $m\to\infty$.

\begin{theorem}
For every $\epsilon > 0$, there exists $\delta > 0$ and $m$ sufficiently large, so that even given a graph $\tilde{\bG}$ which is a $\delta|E|$-perturbation of the edges of some $\bG$, $\LS(2,m)$ can be used to distinguish whether $\bG$ is a uniformly random $d$-regular graph or was drawn from an RSBM $\epsilon$-away from the threshold.
\end{theorem}

Along the way we will inadvertently prove that standard spectral detection using the adjacency matrix succeeds above $d_{KS}$, but cannot have the same robustness guarantee. It is a now-classic result of Friedman that, with probability $1 - o_n(1)$, the spectrum of a uniformly random $d$-regular graph is within $o_n(1)$ of $(-2\sqrt{d-1},2\sqrt{d-1})\cup\{d\}$. Conversely, we show:

\begin{corollary}
	Let $\bG$ be drawn from the RSBM with parameters $(d,k,M,\pi)$, and set $\epsilon > 0$. There exists some $\delta = \delta(\epsilon)$ such that, for each eigenvalue $\lambda$ of $M$ satisfying $|\lambda| > 1/\sqrt{d-1} + \epsilon$, the adjacency matrix $A_{\bG}$  is guaranteed one eigenvalue $\mu$ satisfying $|\mu| > 2\sqrt{d-1} + \delta$.
\end{corollary}

Regrettably, we do not resolve to similar satisfaction the issue of efficient or robust recovery above Kesten-Stigum. The eigenvectors guaranteed to us by Theorem [ref] are certainly correlated to the community structure, and we can prove that the Local Statistics hierarchy can robustly approximate them: 

\begin{theorem}
	In any planted model $\Planted$ for which the $\LS(2,m)$ hierarchy can solve the distinguishing problem, it can robustly approximate the eigenvectors outside the bulk of $A_{\bG}$, for $\bG \sim \Planted$, in the sense that [finish].
\end{theorem}

However, the remaining and technically challenging ingredient is a proof that graphs drawn from the planted model do not accumulate \emph{additional}, spurious eigenvalues outside the bulk. From weak convergence of the empirical spectral distribution of $A_{\bG}$ to the Kesten-McKay law, we know that there must be $o(n)$ eigenvalues with modulus larger than $2\sqrt{d-1}$, but the guarantee of Theorem [ref] only kicks in once there are, i.e. $O(1)$ of them. We believe the following conjecture feasible to prove with a careful mirroring of the techniques in [ref Bordenave], but the execution of this is beyond the scope of the current work.

\begin{conjecture}
	Let $\Planted_{(d,k,M,\pi)}$ be any \model with $|\lambda_1|,...,|\lambda_\ell| > (d-1)^{-1/2}$. Then, for any $\epsilon$, with high probability, $A_{\bG}$ has only $\ell$ eigenvalues with modulus larger than $2\sqrt{d-1} + \epsilon$.
\end{conjecture}

\paragraph{Related Work.}

Semidefinite programming approaches have been most studied in the dense, irregular case, where exact recovery is possible (for instance \cite{abbe2016exact,abbe2015community}), and it has been shown that an SDP relaxation can achieve the information-theoretically optimal threshold \cite{hajek2016achieving}. However, in the sparse regime we consider, the power of SDP relaxations for weak recovery remains unclear. Guedon and Vershynin \cite{guedon2016community} show upper bounds on the estimation error of a standard SDP relaxation in the sparse, two-community case of the SBM, but only when the degree is roughly $10^4$ times the information theoretic threshold. More recently, in a tour-de-force,  Montanari and Sen \cite{montanari2015semidefinite} showed that for two communities, the SDP of Guedon and Vershynin achieves the information theoretically optimal threshold for large but constant degree, in the sense that the performance approaches the threshold if we send the number of vertices, and then the degree, to infinity. \todo{Is this the correct characterization of their results?} Semi-random graph models have been intensively studied in \cite{blum1995coloring, feige2000finding, feige2001heuristics,coja2004coloring,krivelevich2006semirandom,coja2007solving, makarychev2012approximation, chen2014clustering,guedon2016community} and we refer the reader to \cite{makarychev2016learning} for a more detailed survey. In the logarithmic-degree regime, robust algorithms for community detection are developed in \cite{cai2015robust, kumar2010clustering, awasthi2012improved}. Less is known in the case of regular graphs. However, \cite{banks2017lov} show that the Lov\`{a}sz $\vartheta$ function---a strengthening of the SDP we will consider---can distinguish between graphs drawn from the symmetric RSBM and the uniformly random model when $d > 4d_{KS}$.

% section main_results (end)